---
title: "Zillow Smarketing Attribution Project"
author: "Andrea Hellebust, Han Li, Hannah Khuong, Keith Castelino, Mark Russeff, Ying Xue"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: true
---
# Assumption

1. Organic leads are considered as organic regardless of possible prior ads exposure. 
We do not have data on ads impression to attribute how much of organic data is from ads exposure or are they truly organic.
2. We eliminated calls has dial time shorter than 30 second to standardize $10 for a phonecall. 
3. In lead table, all the interactions having LeadVendor/LeadType unknown and NAs under 'Paid' category, were regrouped into 'Unspecified'. All miscellaneous leads (i.e., brandnetworks, MSN_Real_Estate) are regrouped under 'Paid Other'. They might have some valuable information to understand the interaction prior conversion, yet we don't have information for such data.
4. Timezone is consistent. Even though the data is pulled from different sources, we assume all datetime recorded is at a same time zone.
5. In lead table, Twitter, Facebook, Instagram, Linkedin leads are regrouped into 'Paid Social'. 
6. In lead table, 'Organic Social' is considered as 'Organic' and was grouped together. 
7. In call table, missing REAgentID might be due to human errors and were eliminated because AgentID is critial for analysis. 
8. We assume all NPV is the same for other attribution model (even though they were given for last-touch model). We also used averages; more granular NPV data for call and meeting channels were unavailable.



# Data

## Clear working enviroment
```{r warning=FALSE, results='hide'}
# Clear environment of variables and functions
rm(list = ls(all = TRUE)) 

# Clear environmet of packages
if(is.null(sessionInfo()$otherPkgs) == FALSE)lapply(paste("package:", names(sessionInfo()$otherPkgs), sep=""), detach, character.only = TRUE, unload = TRUE)
```
 
## Load Packages
```{r message = FALSE, warning=FALSE}
if (!require("ChannelAttribution")) install.packages("ChannelAttribution")
if (!require("plotly")) install.packages("plotly")
if (!require("jsonlite")) install.packages("jsonlite")
if (!require("reshape")) install.packages("reshape")
library(jsonlite)
library(plotly)
library(readr)
library(tidyverse)
library(ChannelAttribution)
library(ggplot2)
library(reshape)

```

## Load Data

```{r message = FALSE, results='hide'}
#Sales call Dataframes
PhoneCalls20161001_20170228 <- read_csv("PhoneCalls20161001_20170228.csv") #From 2016-10-01 to 2017-02-28
PhoneCalls20170301_20170630 <- read_csv("PhoneCalls20170301_20170630.csv") #From 2017-03-01 to 2017-06-30

#Agent acquisition date by ZUID
agent_acquisition_date <- read_csv("AgentAcquisitionDates.csv")

#AgentID to ZUID mapping
agentid_zuid <- read_csv("AgentIDZUIDLookup.csv")

#Lead table
agent_lead <- read_csv("AgentLeads.csv")

#Sales meeting table
sales_meeting <- read_csv("SalesMeetings.csv")

#Union 2 Call Dataframes. Output: Call Dataframe from 2016-10-01 to 2017-06-30
phone_call <- bind_rows(PhoneCalls20161001_20170228, PhoneCalls20170301_20170630)
```

# Data Preprocessing

## Identify missing values

```{r}
#Function returning the percentage of missing values for each column.
function_count_na <- function(df){
  percent_missing <-sapply(df, function(y) round(100*sum(length(which(is.na(y))))/sum(length(y)),2))
  percent_missing <- data.frame(percent_missing)
  percent_missing
}

function_count_na(phone_call) #REAgentID missing 69.6%, SalesRepID missing 0.5%, 3 other variables no missing data 
function_count_na(agent_lead) 
function_count_na(sales_meeting) #no missing data 
function_count_na(agentid_zuid) #no missing data 
function_count_na(agent_acquisition_date) #Zuid missing 0%, AcquisitionDate missing 14.5%
```

## Check Datetime range
```{r}
#Check date range of agent_lead
max(agent_lead$LeadDateTime) #"2017-06-29 23:30:28 UTC"
min(agent_lead$LeadDateTime) #"2016-10-01 00:00:49 UTC"

#Check date range of agent_acquisition_date
max(na.omit(agent_acquisition_date$AcquisitionDate)) #"2017-07-05 UTC"
min(na.omit(agent_acquisition_date$AcquisitionDate)) #"2009-01-01 UTC"

#Check date range of sales_meeting
max(sales_meeting$SalesMeetingDate) #"2017-06-30 UTC"
min(sales_meeting$SalesMeetingDate) #"2017-03-13 UTC"

```

**Observation**

Lead table:
* From Oct 2017 to June 2017

Acquisition table:
* From Jan 2009 to July 2017
* Solution: Delete data before Oct 2017

Sales Meeting table:
* Only from March 2017 to June 2017 
* Comment: Limited information, might not be information for data before march 2017


```{r}
#Filter agent_acquisition_date before 2016-10-01
agent_acquisition_date <- subset(agent_acquisition_date, AcquisitionDate >= "2016-10-01")

```
Result: 18,086 rows (originally 161,006 rows )  

## Organize and assign Channels
```{r}
#Search for all unique lead vendors
agent_lead %>% group_by(agent_lead$LeadType) %>% distinct(LeadVendor)
```

```{r}
#Clean up marketing channel assignments
agent_lead <-agent_lead %>% mutate(LeadType=replace(LeadType, LeadType== "Social Organic", "Organic"),
                      LeadVendor=replace(LeadVendor, LeadType == "Organic", "Organic"),
                      LeadVendor=replace(LeadVendor, LeadVendor == "organic", "Organic"),
                      LeadVendor=replace(LeadVendor, LeadType == "Organic", "Organic"),
                      LeadVendor=replace(LeadVendor, LeadType == "unknown", "Unspecified"),
                      LeadVendor=replace(LeadVendor, LeadVendor == "unknown", "Unspecified"),
            LeadVendor=replace(LeadVendor, LeadVendor== "Gdn", "Google Search"),
            LeadVendor=replace(LeadVendor, LeadVendor== "GDN", "Google Search"),
            LeadVendor=replace(LeadVendor, LeadVendor== "Affiliate", "Paid Other"),
            LeadVendor=replace(LeadVendor, LeadVendor== "Linkedin Ads", "Linkedin"),
            LeadVendor=replace(LeadVendor, LeadVendor== "Linkedin Display", "Linkedin"),
            LeadVendor=replace(LeadVendor, LeadVendor== "Great_Schools", "Paid Other"),
            LeadVendor=replace(LeadVendor, LeadVendor== "Trulia", "Paid Other"),
            LeadVendor=replace(LeadVendor, LeadVendor== "gemini", "Paid Other"),
            LeadVendor=replace(LeadVendor, LeadVendor== "internal", "Paid Other"),
            LeadVendor=replace(LeadVendor, LeadVendor== "IronTraffic", "Paid Other"),
            LeadVendor=replace(LeadVendor, LeadVendor== "4197532", "Paid Other"),
            LeadVendor=replace(LeadVendor, LeadVendor== "brandnetworks", "Paid Other"),
            LeadVendor=replace(LeadVendor, LeadVendor== "MSN_Real_Estate", "Paid Other"),
            LeadVendor=replace(LeadVendor, LeadVendor== "Unspecified" & LeadType == "Paid", "Paid Other"),
            LeadVendor=replace(LeadVendor, LeadVendor== "http://www.2020propertygroup.com/monthly-payment-calculator/", "Paid Other"),
            LeadVendor=replace(LeadVendor, is.na(LeadVendor) & LeadType == "Paid", "Paid Other"),
            LeadVendor=replace(LeadVendor, LeadVendor== "AreaVibes", "Paid Other"),
            LeadType=replace(LeadType, LeadVendor == "Organic" & LeadType == "Paid", "Paid Other"),
            LeadVendor=replace(LeadVendor, LeadVendor== "facebook" | LeadVendor== "Facebook" | 
                                 LeadVendor== "instagram" |LeadVendor== "Instagram"|
                                 LeadVendor == "Twitter" |LeadVendor== "Linkedin", "Paid Social"),
         LeadVendor=replace(LeadVendor, LeadVendor== "gmail"|LeadVendor == "Gmail" | 
                              LeadVendor == "Outlook" | LeadVendor == "Yahoo", "Email"),
         LeadType=replace(LeadType, LeadVendor== "Email", "Email"),         
         LeadVendor = replace(LeadVendor, LeadType == "Email", "Email"), 
         LeadVendor = replace(LeadVendor, is.na(LeadVendor), "Unspecified"),
         LeadType = replace(LeadType, is.na(LeadType), 'Unspecified'))

#Remove Unspecified non paid channels.
#agent_lead <- subset(agent_lead, LeadVendor != "Unspecified") 

agent_lead
```

## Create an aggregate table for all channels

```{r}
#Create a Marketing Channel aggregate dataframe
Channel_Data <- agent_lead %>% 
  group_by(LeadVendor) %>% 
  summarise(Total = n())

Channel_Data$Cost <- c(80, 10, 100, 0, 110, 150, 0)
Channel_Data$Total_Cost <- Channel_Data$Total*Channel_Data$Cost
Channel_Data$NPV <- c(7000, 8000, 7000, 7500, 7000, 7000, 7500)

#Create a Sales Channel calls aggregate dataframe
Channel_Calls <- phone_call %>% 
  filter(TalkTimeMinutes >= 0.5) %>%
  group_by(PhoneCallType) %>% 
  summarise(Total = n())

Channel_Calls <- Channel_Calls %>% dplyr::rename(LeadVendor = PhoneCallType)
Channel_Calls$Cost <- c(10, 10)
Channel_Calls$Total_Cost <- Channel_Calls$Total*Channel_Calls$Cost
Channel_Calls$NPV <- c(7500, 7500)

#Create a Sales Channel meetings aggregate dataframe
Channel_Meet <- sales_meeting %>% 
  summarise(Total = n())

Channel_Meet$Cost <- c(300)
Channel_Meet$Total_Cost <- Channel_Meet$Total*Channel_Meet$Cost
Channel_Meet$NPV <- c(7500)
Channel_Meet$LeadVendor <- "Meeting"

#Bind into an aggregate channels dataframe that will be useful later.
Channel_Data <- bind_rows(Channel_Data, Channel_Calls, Channel_Meet)
Channel_Data <- Channel_Data %>% 
  arrange(LeadVendor) %>%
  dplyr::rename(channel_name = LeadVendor)
Channel_Data
```

## Join Data

```{r}
#Left join agentid_zuid AND agent_acquisition_date ON zuid 
agentid_zuid_acquisitionDate <- left_join(agentid_zuid, agent_acquisition_date, by = "ZUID")

#Remove all ids without an acquisition date
agentid_zuid_acquisitionDate <- subset(agentid_zuid_acquisitionDate, !is.na(AcquisitionDate || !is.na(REAgentID)))

```

```{r}
#Joing meeting with acquisition date
meeting_with_zuid <- sales_meeting %>% left_join(agentid_zuid_acquisitionDate, by = "REAgentID")
meeting_with_zuid <- meeting_with_zuid %>% filter(AcquisitionDate >= SalesMeetingDate | is.na(AcquisitionDate))
meeting_with_zuid
```

```{r}
#Filter call data to calls over 2 minutes that have agent ids
phone_call<-subset(phone_call, phone_call$TalkTimeMinutes >= 2 & !is.na(REAgentID))

#Joing meeting with acquisition date
phoneCall_with_zuid <- phone_call %>% left_join(agentid_zuid_acquisitionDate, by = "REAgentID")
phoneCall_with_zuid <- subset(phoneCall_with_zuid, PhoneCallDateTime < AcquisitionDate | is.na(AcquisitionDate) | !is.na(REAgentID))
phoneCall_with_zuid
```

```{r}
#Joing leads with acquisition date
lead_with_zuid <- left_join(agent_lead, agentid_zuid_acquisitionDate, by = "REAgentID")
lead_with_zuid <- subset(lead_with_zuid, LeadDateTime < AcquisitionDate || is.na(AcquisitionDate) || !is.na(REAgentID))
lead_with_zuid
```

```{r}
#Creating dataframes that can be bound together
meeting <- meeting_with_zuid %>%
  select(REAgentID, SalesMeetingDate, AcquisitionDate) %>%
  dplyr::rename(Date = SalesMeetingDate)

phone <- phoneCall_with_zuid %>%
  select(REAgentID, PhoneCallType, PhoneCallDateTime, AcquisitionDate) %>%
  dplyr::rename(Channel = PhoneCallType, Date = PhoneCallDateTime)

leads <- lead_with_zuid %>%
  select(REAgentID, LeadVendor, LeadDateTime, AcquisitionDate) %>%
  dplyr::rename(Channel = LeadVendor, Date = LeadDateTime)

master <- bind_rows(leads, phone, meeting)

#Replace NA in Channel column
master$Channel[is.na(master$Channel)] <- "Meeting"

master <- master %>% filter(!is.na(REAgentID)) %>%
  mutate(Conversion = ifelse(is.na(AcquisitionDate), 0, 1))

  
master
```
# EDA

## Customer journey to conversion statistics

```{r}

#Add the average touches and average time
stats <- master %>% 
  filter(Conversion == 1) %>%
  arrange(REAgentID, Date) %>%
  group_by(REAgentID) %>% 
  summarise(Touch = n(), Days = (max(Date) - min(Date))) 
  
stats %>% summarise(Average_Touch = mean(Touch),
                    Max_Touch = max(Touch),
                    Average_Days = mean(Days),
                    Max_Days = max(Days)) 

```
```{r}
#Distribution plot for days to conversion.
ggplot(stats %>% filter(Days > 0), aes(x = Days)) +
        theme_minimal() +
        geom_histogram(fill = '#4e79a7', binwidth = 7)
```
```{r}
#Distribution plot for touches to conversion.
ggplot(stats, aes(x = Touch)) +
        theme_minimal() +
        geom_histogram(fill = '#4e79a7', binwidth = 1)
```

# Analysis

```{r}
# aggregating channels to the paths for each customer
paths <- master %>%
        filter(!is.na(REAgentID)) %>%
        arrange(REAgentID, Date) %>%
        group_by(REAgentID) %>%
        summarise(path = paste(Channel, collapse = ' > '),
                  conv = mean(Conversion)) %>%
        ungroup()
paths
```

## Build the smarketing attribution models

```{r}
#Calculating the Markov model
markov <- markov_model(paths,
                    var_path = 'path',
                    var_conv = 'conv',
                    out_more = TRUE)

#Calculating the other models
h_mod <- heuristic_models(paths, 
                           var_path = 'path', 
                           var_conv = 'conv')

#Merges the two data frames on the "channel_name" column.
results <- merge(h_mod, markov$result, by='channel_name') 

#Rename the columns
colnames(results) <- c('channel_name', 'first_touch', 'last_touch', 'linear_touch', 'markov_model') 

results


#Transforms the dataset into a data frame that ggplot2 can use to graph the outcomes
results_graph <- melt(results, id='channel_name')
```
```{r}
# Plot the total conversions
ggplot(results_graph, aes(x = reorder(channel_name, value), y = value, fill =variable)) +
  geom_bar(stat='identity', position='dodge') +
  ggtitle('Total Conversions') + 
  theme(panel.grid.major = element_blank(),
      panel.grid.minor = element_blank()) +
  coord_flip() +
  theme_classic() +
  scale_fill_manual(values = c("#08519c","#3182bd","#6baed6", "#bdd7e7")) +
  theme(axis.text = element_text(face = "bold", size = 10),
      axis.title = element_blank(),
      axis.ticks.x = element_blank(),
      legend.title = element_text(face = "bold"),
      legend.position = c(0.9, 0.2),
      plot.title = element_text(hjust=0.5, face ="bold"),
      plot.subtitle = element_text(hjust = 0.5)) 
```

### Results for last touch attribution.

```{r}
#Listing the results for the last touch attribution for smarketing
results %>% select(channel_name, last_touch) %>%
  mutate(conversion_rate = last_touch/Channel_Data$Total) %>%
  mutate(CPA = Channel_Data$Total_Cost/last_touch) %>%
  mutate(ROI = ((Channel_Data$NPV*last_touch) / Channel_Data$Total_Cost))
```

### Results for first touch attribution.

```{r}
#Listing the results for the first touch attribution for smarketing
results %>% select(channel_name, first_touch) %>%
  mutate(conversion_rate = first_touch/Channel_Data$Total) %>%
  mutate(CPA = Channel_Data$Total_Cost/first_touch) %>%
  mutate(ROI = ((Channel_Data$NPV*first_touch) / Channel_Data$Total_Cost))
```

### Results for linear attribution

```{r}
#Listing the results for the linear attribution model for smarketing
results %>% select(channel_name, linear_touch) %>%
  mutate(conversion_rate = linear_touch/Channel_Data$Total) %>%
  mutate(CPA = Channel_Data$Total_Cost/linear_touch) %>%
  mutate(ROI = ((Channel_Data$NPV*linear_touch) / Channel_Data$Total_Cost))
```

### Results for the markov chain model

```{r}
#Listing the results for the markov chain attribution for smarketing
results %>% select(channel_name, markov_model) %>%
  mutate(conversion_rate = markov_model/Channel_Data$Total) %>%
  mutate(CPA = Channel_Data$Total_Cost/markov_model) %>%
  mutate(ROI = ((Channel_Data$NPV*markov_model) / Channel_Data$Total_Cost))
```

### ROI for each attribution strategy

```{r}
results_ROI <- results %>% 
  mutate(first_ROI = (Channel_Data$NPV*first_touch) / Channel_Data$Total_Cost) %>%
  mutate(last_ROI = (Channel_Data$NPV*last_touch) / Channel_Data$Total_Cost) %>%
  mutate(linear_ROI = (Channel_Data$NPV*linear_touch) / Channel_Data$Total_Cost) %>%
  mutate(markov_ROI = (Channel_Data$NPV*markov_model) / Channel_Data$Total_Cost) %>%
  select(channel_name, first_ROI, last_ROI, linear_ROI, markov_ROI) %>%
  filter(channel_name != "Organic" & channel_name != "Unspecified")

results_ROI
```

### Graph ROI accross channels

```{r}

#Transforms the dataset into a data frame that ggplot2 can use to graph the outcomes
results_ROI <- melt(results_ROI, id='channel_name')

# Plot the ROIs
ggplot(results_ROI, aes(x = reorder(channel_name, value), y = value, fill =variable)) +
  geom_bar(stat='identity', position='dodge') +
  ggtitle('ROI Per Channel') + 
  theme(panel.grid.major = element_blank(),
      panel.grid.minor = element_blank()) +
  coord_flip() +
  theme_classic() +
  scale_fill_manual(values = c("#08519c","#3182bd","#6baed6", "#bdd7e7")) +
  theme(axis.text = element_text(face = "bold", size = 10),
      axis.title = element_blank(),
      axis.ticks.x = element_blank(),
      legend.title = element_text(face = "bold"),
      legend.position = c(0.9, 0.2),
      plot.title = element_text(hjust=0.5, face ="bold"),
      plot.subtitle = element_text(hjust = 0.5)) 
```


## Build the attribution models for marketing channels only

```{r}
marketing_master <- master %>% filter(Channel != "Meeting" & Channel != "RE Agent Called Sales Rep" & Channel != "Sales Rep Called RE Agent")

# aggregating channels to the paths for each customer
paths2 <- marketing_master %>%
        arrange(REAgentID, Date) %>%
        group_by(REAgentID) %>%
        summarise(path = paste(Channel, collapse = ' > '),
                  conv = mean(Conversion)) %>%
        ungroup()
```


```{r}
#Calculating the Markov model
markov <- markov_model(paths2,
                    var_path = 'path',
                    var_conv = 'conv',
                    out_more = TRUE)

#Calculating the other models
h_mod <- heuristic_models(paths2, 
                           var_path = 'path', 
                           var_conv = 'conv')

#Merges the two data frames on the "channel_name" column.
results2 <- merge(h_mod, markov$result, by='channel_name') 

#Rename the columns
colnames(results2) <- c('channel_name', 'first_touch', 'last_touch', 'linear_touch', 'markov_model') 

results2


#Transforms the dataset into a data frame that ggplot2 can use to graph the outcomes
results2_graph <- melt(results2, id='channel_name')
```

### Results for last touch attribution

```{r}
m_channel <- Channel_Data %>% filter(channel_name != "Meeting" & channel_name != "Sales Rep Called RE Agent" & channel_name != "RE Agent Called Sales Rep")

results2 %>% select(channel_name, last_touch) %>%
  mutate(conversion_rate = last_touch/m_channel$Total) %>%
  mutate(CPA = m_channel$Total_Cost/last_touch) %>%
  mutate(ROI = (m_channel$NPV*last_touch) / m_channel$Total_Cost)
```

### Results for markov chain attribution

```{r}
results2 %>% select(channel_name, markov_model) %>%
  mutate(conversion_rate = markov_model/m_channel$Total) %>%
  mutate(CPA = m_channel$Total_Cost/markov_model) %>%
  mutate(ROI = (m_channel$NPV*markov_model) / m_channel$Total_Cost)
```

```{r}
# Plot the total conversions
ggplot(results2_graph, aes(channel_name, value, fill = variable)) +
  geom_bar(stat='identity', position='dodge') +
  ggtitle('Total Conversions') + 
  theme(panel.grid.major = element_blank(),
      panel.grid.minor = element_blank()) +
  theme_classic() +
  scale_fill_manual(values = c("#08519c","#3182bd","#6baed6", "#bdd7e7")) +
  theme(axis.text = element_text(face = "bold", size = 10),
      axis.title = element_blank(),
      axis.ticks.x = element_blank(),
      legend.title = element_text(face = "bold"),
      legend.position = c(0.9, 0.8),
      plot.title = element_text(hjust=0.5, face ="bold"),
      plot.subtitle = element_text(hjust = 0.5)) 
```

# Visualize Path with Sankey diagram

```{r message = FALSE, error = FALSE, warning=FALSE, fig.height= 8, fig.width=8}
# Construct conversions sequences for all visitors
master1 = master %>%
  group_by(REAgentID) %>%
  arrange(Date) %>%
  mutate(order_seq = ifelse(Conversion > 0, 1, NA)) %>%
  mutate(order_seq = lag(cumsum(ifelse(is.na(order_seq), 0, order_seq)))) %>%
  mutate(order_seq = ifelse((row_number() == 1) & (Conversion > 0), 
    -1, ifelse(row_number() == 1, 0, order_seq))) %>% 
  ungroup()

# Create a modified channel stacks data frame
channel_stacks = master1 %>%
  group_by(REAgentID, order_seq) %>%
  
  #first remove irrelevant hits:
  filter(!is.na(Channel) | Conversion>0) %>%
  
  #next remove repeated values with a lag function:
  filter((Channel != lag(Channel, default="1")) | Conversion>0) %>%
  
  #now concatenate the sequence into a single row:
  summarize(
    path = paste(Channel[which(!is.na(Channel))], collapse=">"),
    
    # for Spark SQL or PostgreSQL:
    # path = concat_ws(" > ", collect_list(Channel))
    
    Conversion = sum(Conversion)
  ) %>% ungroup() %>%
  
  #next roll up each unique path by count and conversion:
  group_by(path) %>%
  summarize(
    Conversion = sum(Conversion),
    path_count = n()
  ) %>% ungroup() %>%
  
  #last create a conversion rate column and pull it out of Spark:
  mutate(
    conversion_rate = Conversion/path_count
  ) %>%
  filter(path != "") %>%
  collect()


# Visualizing customer paths with a Sankey Diagram
# Creating a list of channels for convinience
channel_stacks$path_list = strsplit(x=channel_stacks$path,split=">")
# set the depth of the Sankey Diagram
depth = 7
#Generate node labels and label length vectors
node_labels=rep(list(list()),depth)
label_length = list()
for(i in 1:depth){
  for(j in 1:length(channel_stacks$path)){
    if(!is.na(channel_stacks$path_list[j][[1]][i]))
      node_labels[[i]][j] = channel_stacks$path_list[j][[1]][i]
  }
  node_labels[[i]] = unique(unlist(node_labels[[i]]))
  node_labels[[i]] = node_labels[[i]][order(node_labels[[i]])]
  label_length[[i]] = length(node_labels[[i]])
}
node_labels = unlist(node_labels)
label_length = unlist(label_length)


# Build a data frame to fill out with each path view
combos = NULL
for(i in 1:(depth-1)){
  for(j in (1 + sum(label_length[1:i-1])):(label_length[i] + sum(label_length[1:i-1]))){
    for(k in (1 + label_length[i] + sum(label_length[1:i-1])):(label_length[i+1] + label_length[i] + sum(label_length[1:i-1]))){
      combos = rbind(combos, c(i,j,k,0))
    } 
  }
}
combos = as.data.frame(combos)
names(combos) = c("step","source","target","value")
#Populate the combo table
for(i in 1:(dim(combos)[1])){
  for(j in 1:(dim(channel_stacks)[1])){
    combos$value[i] = sum(combos$value[i], ifelse(
      (node_labels[combos$source[i]] == channel_stacks$path_list[j][[1]][combos$step[i]]) &
      (node_labels[combos$target[i]] == channel_stacks$path_list[j][[1]][combos$step[i]+1]),
      channel_stacks$path_count[j],0), na.rm = TRUE)
  }
}


#Add a node to populate with conversion values
uniques = unique(c(combos$source,combos$target))
converts = as.data.frame(list("step"=rep(0,length(uniques)), "source"=uniques, "target"=rep(max(uniques)+1,length(uniques)), "value"=rep(0,length(uniques))))
combos = rbind(combos,converts)
for(i in 1:(dim(channel_stacks)[1])){
  stack_depth = min(depth,length(channel_stacks$path_list[i][[1]]))
  index_val = which(combos$step==0 & combos$source==(which(node_labels == channel_stacks$path_list[i][[1]][stack_depth]) + ifelse(stack_depth>1, sum(label_length[1:(stack_depth-1)]),0)))
  combos$value[index_val] = combos$value[index_val] + channel_stacks$Conversion[i]
}
#Populate the conversion node values
display_node_labels = node_labels
for(i in 1:length(label_length)){
  for(j in 1:label_length[i]){
    display_node_labels[j+ifelse(i==1,0,sum(label_length[1:(i-1)]))] = paste0(i,":",node_labels[j+ifelse(i==1,0,sum(label_length[1:(i-1)]))])
  }
}
display_node_labels = c(display_node_labels, "Conversion")

#Generate Sankey diagram
p <- plot_ly(
    type = "sankey",
    orientation = "v",
    node = list(
      label = display_node_labels,
      #color = node_colors,
      pad = 10,
      thickness = 30,
      line = list(
        color = "white",
        width = 0
      )
    ),
  
    link = list(
      source = combos$source-1, # convert to zero index
      target = combos$target-1, # convert to zero index
      value = combos$value, #size of connection
      color = "rgba(0, 0, 0, 0.2)"
    )
  ) %>% 
  layout(
    title = "Conversion Flow Diagram",
    font = list(
    size = 10
    )
  )
p
```





